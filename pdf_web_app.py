#!/usr/bin/env python3
"""PDFåˆ†å‰²å·¥å…· """
import os
import sys
import json
import threading
import webbrowser
from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for
from werkzeug.utils import secure_filename
import zipfile
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_dir)

from pdf_processor import PDFProcessor, LargeFilePDFProcessor, comprehensive_integrity_check, create_integrity_report
from pdf_chapter_splitter import PDFChapterSplitter, validate_pdf_integrity
from PIL import Image
import base64
from io import BytesIO

app = Flask(__name__)
app.config['SECRET_KEY'] = 'pdf_splitter_secret_key'
app.config['UPLOAD_FOLDER'] = os.path.join(tempfile.gettempdir(), 'pdf_uploads')
app.config['OUTPUT_FOLDER'] = os.path.join(tempfile.gettempdir(), 'pdf_outputs')

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['OUTPUT_FOLDER'], exist_ok=True)

# å…¨å±€å˜é‡å­˜å‚¨å¤„ç†çŠ¶æ€
processing_status = {
    'is_processing': False,
    'progress': 0,
    'message': 'å‡†å¤‡å°±ç»ª',
    'files': [],
    'error': None
}

def progress_callback(current, total, status_info=None):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    global processing_status
    processing_status['progress'] = int((current / total) * 100)
    if status_info and 'extra_info' in status_info:
        processing_status['message'] = status_info['extra_info']

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼  - æ”¯æŒå•æ–‡ä»¶å’Œå¤šæ–‡ä»¶"""
    global processing_status
    
    if 'files' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
    
    files = request.files.getlist('files')
    if not files or files[0].filename == '':
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
    
    uploaded_files = []
    
    for file in files:
        if file and file.filename.lower().endswith('.pdf'):
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            try:
                # è·å–æ–‡ä»¶ä¿¡æ¯
                file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
                if file_size_mb > 100:
                    processor = LargeFilePDFProcessor()
                else:
                    processor = PDFProcessor()
                
                page_count, file_size_mb, detailed_info = processor.get_pdf_info(filepath)
                
                uploaded_files.append({
                    'filename': filename,
                    'filepath': filepath,
                    'page_count': page_count,
                    'file_size_mb': round(file_size_mb, 2),
                    'is_large_file': detailed_info.get('is_large_file', False),
                    'avg_page_size_kb': round(detailed_info.get('avg_page_size_kb', 0), 1)
                })
                
            except Exception as e:
                return jsonify({'error': f'æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}'})
    
    if not uploaded_files:
        return jsonify({'error': 'æ²¡æœ‰æœ‰æ•ˆçš„PDFæ–‡ä»¶'})
    
    return jsonify({
        'success': True,
        'files': uploaded_files,
        'count': len(uploaded_files)
    })

@app.route('/preview_pdf', methods=['POST'])
def preview_pdf():
    """é¢„è§ˆPDFæ–‡ä»¶å†…å®¹"""
    filepath = request.json.get('filepath')
    page_num = request.json.get('page', 1)  # é»˜è®¤é¢„è§ˆç¬¬ä¸€é¡µ
    
    if not filepath or not os.path.exists(filepath):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'})
    
    try:
        import fitz  # PyMuPDF
        
        # æ‰“å¼€PDFæ–‡ä»¶
        doc = fitz.open(filepath)
        if page_num < 1 or page_num > len(doc):
            page_num = 1
        
        # è·å–æŒ‡å®šé¡µé¢
        page = doc[page_num - 1]
        
        # æ¸²æŸ“é¡µé¢ä¸ºå›¾åƒ
        mat = fitz.Matrix(1.5, 1.5)  # ç¼©æ”¾å› å­
        pix = page.get_pixmap(matrix=mat)
        img_data = pix.tobytes("png")
        
        # è½¬æ¢ä¸ºbase64
        img_base64 = base64.b64encode(img_data).decode('utf-8')
        
        doc.close()
        
        return jsonify({
            'success': True,
            'preview_image': f"data:image/png;base64,{img_base64}",
            'current_page': page_num,
            'total_pages': len(doc)
        })
        
    except ImportError:
        # å¦‚æœPyMuPDFä¸å¯ç”¨ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        return jsonify({
            'success': False,
            'error': 'é¢„è§ˆåŠŸèƒ½éœ€è¦å®‰è£…PyMuPDFåº“',
            'fallback': True
        })
    except Exception as e:
        return jsonify({'error': f'é¢„è§ˆå¤±è´¥: {str(e)}'})

@app.route('/preview_chapters', methods=['POST'])
def preview_chapters():
    """é¢„è§ˆç« èŠ‚"""
    filepath = request.json.get('filepath')
    
    if not filepath or not os.path.exists(filepath):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'})
    
    try:
        file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
        if file_size_mb > 100:
            processor = LargeFilePDFProcessor()
        else:
            processor = PDFProcessor()
        
        chapters = processor.preview_chapters(filepath)
        
        return jsonify({
            'success': True,
            'chapters': chapters
        })
        
    except Exception as e:
        return jsonify({'error': f'ç« èŠ‚é¢„è§ˆå¤±è´¥: {str(e)}'})

@app.route('/split', methods=['POST'])
def split_pdf():
    """æ‰§è¡ŒPDFåˆ†å‰² - æ”¯æŒæ‰¹é‡å¤„ç†"""
    global processing_status
    
    if processing_status['is_processing']:
        return jsonify({'error': 'æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™'})
    
    data = request.json
    files_data = data.get('files', [])  # æ‰¹é‡æ–‡ä»¶æ•°æ®
    custom_output_path = data.get('output_path', '')  # è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
    
    if not files_data:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
    
    # éªŒè¯æ‰€æœ‰æ–‡ä»¶å­˜åœ¨
    for file_data in files_data:
        filepath = file_data.get('filepath')
        if not filepath or not os.path.exists(filepath):
            return jsonify({'error': f'æ–‡ä»¶ä¸å­˜åœ¨: {file_data.get("filename", "æœªçŸ¥")}'})
    
    # é‡ç½®çŠ¶æ€
    processing_status = {
        'is_processing': True,
        'progress': 0,
        'message': 'å¼€å§‹æ‰¹é‡å¤„ç†...',
        'files': [],
        'error': None,
        'current_file': '',
        'total_files': len(files_data)
    }
    
    def process_in_background():
        global processing_status
        
        try:
            all_output_files = []
            total_files = len(files_data)
            
            # ç¡®å®šè¾“å‡ºåŸºç¡€ç›®å½•
            if custom_output_path and os.path.isdir(custom_output_path):
                base_output_dir = custom_output_path
            else:
                base_output_dir = app.config['OUTPUT_FOLDER']
            
            # å¤„ç†æ¯ä¸ªæ–‡ä»¶
            for file_index, file_data in enumerate(files_data):
                filepath = file_data['filepath']
                filename = file_data['filename']
                mode = file_data.get('mode', 'pages')
                
                # æ›´æ–°è¿›åº¦
                processing_status['current_file'] = filename
                processing_status['message'] = f'å¤„ç†æ–‡ä»¶ {file_index + 1}/{total_files}: {filename}'
                processing_status['progress'] = int((file_index / total_files) * 90)
                
                # åˆ›å»ºæ–‡ä»¶ä¸“ç”¨è¾“å‡ºç›®å½•
                file_base_name = os.path.splitext(filename)[0]
                output_dir = os.path.join(base_output_dir, f"{file_base_name}_split")
                os.makedirs(output_dir, exist_ok=True)
                
                # é€‰æ‹©å¤„ç†å™¨
                file_size_mb = file_data['file_size_mb']
                if file_size_mb > 100:
                    processor = LargeFilePDFProcessor(progress_callback=progress_callback)
                else:
                    processor = PDFProcessor(progress_callback=progress_callback)
                
                file_output = []
                
                # æ ¹æ®æ¨¡å¼æ‰§è¡Œåˆ†å‰²
                if mode == 'pages':
                    pages_per_file = file_data.get('pages_per_file', 10)
                    file_output = processor.split_by_pages(filepath, output_dir, pages_per_file)
                    
                elif mode == 'size':
                    target_size_mb = file_data.get('target_size_mb', 5.0)
                    file_output = processor.split_by_size(filepath, output_dir, target_size_mb)
                    
                elif mode == 'range':
                    ranges_str = file_data.get('page_ranges', '')
                    ranges = parse_page_ranges(ranges_str)
                    file_output = processor.split_by_range(filepath, output_dir, ranges)
                    
                elif mode == 'chapter':
                    auto_detect = file_data.get('auto_detect', True)
                    custom_chapters = file_data.get('custom_chapters') if not auto_detect else None
                    file_output = processor.split_by_chapters(filepath, output_dir, auto_detect, custom_chapters)
                
                all_output_files.extend(file_output)
            
            # æœ€ç»ˆå¤„ç†
            processing_status['message'] = 'æ­£åœ¨åˆ›å»ºä¸‹è½½åŒ…...'
            processing_status['progress'] = 95
            
            # åˆ›å»ºæ‰¹é‡ä¸‹è½½åŒ…
            if total_files == 1:
                zip_filename = os.path.splitext(files_data[0]['filename'])[0]
            else:
                zip_filename = f"batch_split_{total_files}_files"
            
            zip_path = create_download_package(all_output_files, zip_filename)
            
            # å®ŒæˆçŠ¶æ€
            status_message = f'æ‰¹é‡åˆ†å‰²å®Œæˆï¼å¤„ç†äº†{total_files}ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆäº†{len(all_output_files)}ä¸ªåˆ†å‰²æ–‡ä»¶'
            
            processing_status.update({
                'is_processing': False,
                'progress': 100,
                'message': status_message,
                'files': [os.path.basename(f) for f in all_output_files],
                'download_path': zip_path,
                'processed_files': total_files,
                'output_files_count': len(all_output_files),
                'save_location': base_output_dir
            })
            
        except Exception as e:
            processing_status.update({
                'is_processing': False,
                'progress': 0,
                'message': 'å¤„ç†å¤±è´¥',
                'error': str(e)
            })
    
    # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†
    thread = threading.Thread(target=process_in_background)
    thread.daemon = True
    thread.start()
    
    return jsonify({'success': True, 'message': 'å¼€å§‹å¤„ç†'})

@app.route('/status')
def get_status():
    """è·å–å¤„ç†çŠ¶æ€"""
    return jsonify(processing_status)

@app.route('/download')
def download_files():
    """ä¸‹è½½åˆ†å‰²åçš„æ–‡ä»¶"""
    download_path = processing_status.get('download_path')
    
    if download_path and os.path.exists(download_path):
        return send_file(download_path, as_attachment=True, 
                        download_name=f"pdf_split_{os.path.basename(download_path)}")
    
    return jsonify({'error': 'ä¸‹è½½æ–‡ä»¶ä¸å­˜åœ¨'})

def parse_page_ranges(ranges_str):
    """è§£æé¡µé¢èŒƒå›´å­—ç¬¦ä¸²"""
    ranges = []
    if not ranges_str.strip():
        raise ValueError("é¡µé¢èŒƒå›´ä¸èƒ½ä¸ºç©º")
    
    parts = ranges_str.split(',')
    for part in parts:
        part = part.strip()
        if '-' in part:
            start, end = part.split('-', 1)
            start_page = int(start.strip())
            end_page = int(end.strip())
            if start_page <= 0 or end_page <= 0 or start_page > end_page:
                raise ValueError(f"æ— æ•ˆçš„é¡µé¢èŒƒå›´: {part}")
            ranges.append((start_page, end_page))
        else:
            page_num = int(part)
            if page_num <= 0:
                raise ValueError(f"æ— æ•ˆçš„é¡µé¢å·: {part}")
            ranges.append((page_num, page_num))
    
    return ranges

def create_download_package(output_files, base_name):
    """åˆ›å»ºä¸‹è½½åŒ…"""
    zip_path = os.path.join(app.config['OUTPUT_FOLDER'], f"{base_name}_split.zip")
    
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in output_files:
            if os.path.exists(file_path):
                arcname = os.path.basename(file_path)
                zipf.write(file_path, arcname)
    
    return zip_path

def start_web_app():
    """å¯åŠ¨Webåº”ç”¨"""
    print("=" * 60)
    print("       PDFåˆ†å‰²å·¥å…· - çº¯é»‘ç™½ç®€çº¦ç‰ˆ")
    print("=" * 60)
    print("âœ“ PDFåˆ†å‰²åŠŸèƒ½")
    print("âœ“ å®æ—¶è¿›åº¦ç›‘æ§")
    print("=" * 60)
    
    # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    def open_browser():
        webbrowser.open('http://127.0.0.1:5002')
    
    timer = threading.Timer(1.5, open_browser)
    timer.start()
    
    print("ğŸš€ å¯åŠ¨WebæœåŠ¡å™¨...")
    print("ğŸ“± æµè§ˆå™¨å°†è‡ªåŠ¨æ‰“å¼€: http://127.0.0.1:5002")
    print("ğŸ’¡ å¦‚æœæµè§ˆå™¨æœªè‡ªåŠ¨æ‰“å¼€ï¼Œè¯·æ‰‹åŠ¨è®¿é—®ä¸Šè¿°åœ°å€")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    
    try:
        app.run(host='127.0.0.1', port=5002, debug=True)
    except KeyboardInterrupt:
        print("\n\næœåŠ¡å™¨å·²åœæ­¢")

if __name__ == '__main__':
    start_web_app()